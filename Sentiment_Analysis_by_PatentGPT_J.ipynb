{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Jason Lee, 2022-05-15, for Patent-GPT-J project\n",
        "\n",
        "* The following is based on https://github.com/kingoflolz/mesh-transformer-jax/blob/master/device_sample.py\n",
        "\n",
        "* The purpose of this code is to show that PatentGPT-J is capable of doing sentiment analysis in few-shot learning. \n",
        "\n",
        "* Tested ok: PatentGPT-J-279M and PatentGPT-J-456M.\n",
        "  * PatentGPT-J-1.6B is out of memory even on Colab Pro. (not tested: Colab Pro+)\n",
        "\n",
        "* Reference: \n",
        "  * https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb#scrollTo=n7xAFw-LOYfe\n",
        "Reference: \n",
        "  * https://colab.research.google.com/drive/17zvUhLcpjUKJdTRg00HYdGMEN3uoMy-M?usp=sharing#scrollTo=Wg3x-WQStYHC\n",
        "  * https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/GPT-J-6B/Inference_with_GPT_J_6B.ipynb#scrollTo=PYeldWLtFlvi\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "emiqFMTcQNg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proj = \"PatentGPT-J-456M\" #@param [\"PatentGPT-J-456M\", \"PatentGPT-J-279M\", \"GPT-J-6B\"]"
      ],
      "metadata": {
        "id": "Hjd4yKgKbpNh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g_AASGzBpkR-",
        "outputId": "53a2dbef-9f2f-42af-9a7b-b4f4cf6f9a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  zstd\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 278 kB of archives.\n",
            "After this operation, 1,141 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 zstd amd64 1.3.3+dfsg-2ubuntu1.2 [278 kB]\n",
            "Fetched 278 kB in 1s (337 kB/s)\n",
            "Selecting previously unselected package zstd.\n",
            "(Reading database ... 155203 files and directories currently installed.)\n",
            "Preparing to unpack .../zstd_1.3.3+dfsg-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Setting up zstd (1.3.3+dfsg-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting jaxlib==0.1.67\n",
            "  Downloading jaxlib-0.1.67-cp37-none-manylinux2010_x86_64.whl (45.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.3 MB 22 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (1.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jaxlib==0.1.67) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (1.21.6)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.3.7+cuda11.cudnn805\n",
            "    Uninstalling jaxlib-0.3.7+cuda11.cudnn805:\n",
            "      Successfully uninstalled jaxlib-0.3.7+cuda11.cudnn805\n",
            "Successfully installed jaxlib-0.1.67\n",
            "Collecting jax==0.2.12\n",
            "  Downloading jax-0.2.12.tar.gz (590 kB)\n",
            "\u001b[K     |████████████████████████████████| 590 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (1.0.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax==0.2.12) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax==0.2.12) (1.21.6)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.2.12-py3-none-any.whl size=682487 sha256=b56aaa9724e3ccf52dbd271ea9dd8e5e49af1cec90f7465b29f23618cb4275f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/4d/e5/73eec5070b77f25664c67bd793d4eb97f41bbf9be7afafd15e\n",
            "Successfully built jax\n",
            "Installing collected packages: jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.3.8\n",
            "    Uninstalling jax-0.3.8:\n",
            "      Successfully uninstalled jax-0.3.8\n",
            "Successfully installed jax-0.2.12\n",
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 87.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0) (1.5.2)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 86.5 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68717 sha256=562d2a5593c260636a0c49e50b191d6c8381342bf95c8e5edd62e31417cf685a\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.0\n",
            "    Uninstalling wrapt-1.14.0:\n",
            "      Successfully uninstalled wrapt-1.14.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-2.5.0 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▊                             | 10 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 118 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 638 kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 83.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 74.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 65.6 MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 51.5 MB 114.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 75.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 201 kB 88.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 81.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 128 kB 83.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 74.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 76.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 241 kB 84.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 83.8 MB/s \n",
            "\u001b[?25h  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 107 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 1.6 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.0 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.0 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.0 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.3.2 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 287 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting chex==0.1.2\n",
            "  Downloading chex-0.1.2-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 701 kB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (0.1.67)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (0.2.12)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (0.15.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (0.11.2)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (0.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.9.0->chex==0.1.2) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (0.15.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->chex==0.1.2) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (0.15.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex==0.1.2) (1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->chex==0.1.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (1.19.5)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from chex==0.1.2) (1.19.5)\n",
            "Installing collected packages: chex\n",
            "  Attempting uninstall: chex\n",
            "    Found existing installation: chex 0.1.3\n",
            "    Uninstalling chex-0.1.3:\n",
            "      Successfully uninstalled chex-0.1.3\n",
            "Successfully installed chex-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!apt install zstd\n",
        "!pip install -q pip==20.3.1\n",
        "# for avoiding --> pip takes too long to resolve conflicting dependencies\n",
        "# https://github.com/pypa/pip/issues/9517\n",
        "\n",
        "!pip install jaxlib==0.1.67 \n",
        "!pip install jax==0.2.12\n",
        "!pip install tensorflow==2.5.0   # 2.8.0 won't work?\n",
        "\n",
        "#jax==0.2.22, not workable \n",
        "#!pip install -q \"jax[tpu]>=0.2.16\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
        "\n",
        "!pip install -q optax==0.0.9\n",
        "!pip install -q transformers==4.18.0\n",
        "!pip install -q ray[default]==1.5.1\n",
        "!pip install -q smart_open[gcs]\n",
        "!pip install -q dm-haiku==0.0.5\n",
        "!pip install -q einops==0.3.0\n",
        "\n",
        "!pip install chex==0.1.2\n",
        "# Chex 0.1.3 doesn't support JAX 0.2.12. You need to downgrade to Chex 0.1.2\n",
        "# https://github.com/kingoflolz/mesh-transformer-jax/issues/221\n",
        "# https://github.com/kingoflolz/mesh-transformer-jax/issues/43"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import transformers\n",
        "\n",
        "#proj = 'PatentGPT-J-1.6B'  # out of memory on Colab Pro\n",
        "#proj = 'GPT-J-6B'  # https://github.com/kingoflolz/mesh-transformer-jax\n",
        "\n",
        "params_file = ''\n",
        "params_dict = {'PatentGPT-J-279M':'pgj_d_1024_layer_14.json', \n",
        "               'PatentGPT-J-456M': 'pgj_d_1024.json', \n",
        "               'PatentGPT-J-1.6B': 'pgj_d_2048.json'}\n",
        "\n",
        "print('project: %s' % proj)\n",
        "if proj.startswith('PatentGPT'):               \n",
        "  params_file = params_dict[proj]\n",
        "  size = proj[proj.find('-J-')+3:]\n",
        "  url_params = f'https://huggingface.co/patent/patentgpt-j-{size}/raw/main/{params_file}' \n",
        "  if os.path.exists(params_file) == False:\n",
        "    !wget $url_params\n",
        "    print('Downloaded: %s' % params_file)\n",
        "  else:\n",
        "    print('Existed: %s' % params_file)\n",
        "\n",
        "  encoder_path = 'bpe_output'\n",
        "  url_bpe = f'https://huggingface.co/patent/patentgpt-j-{size}/resolve/main/{encoder_path}.tgz'\n",
        "  if os.path.exists(encoder_path) == False:\n",
        "    !wget $url_bpe\n",
        "    cmd = f\"tar xvfz {encoder_path}.tgz\"\n",
        "    !$cmd     \n",
        "    print('Downloaded: %s' % encoder_path)\n",
        "  else:\n",
        "    print('Existed: %s' % encoder_path)\n",
        "  #tokenizer = transformers.GPT2TokenizerFast(tokenizer_file='%s/tokenizer.json' % encoder_path)\n",
        "\n",
        "  ckpt_folder = 'step_350000/'\n",
        "  if proj in ['PatentGPT-J-456M', 'PatentGPT-J-279M']:\n",
        "    url_step = f'https://huggingface.co/patent/patentgpt-j-{size}/resolve/main/step.tgz'\n",
        "    if os.path.exists(ckpt_folder):\n",
        "      print('Existed: %s' % ckpt_folder)\n",
        "    else:\n",
        "      !wget $url_step\n",
        "  elif proj == 'PatentGPT-J-1.6B': \n",
        "    # a single file is too large --> split into multiple files\n",
        "    if os.path.exists(ckpt_folder):\n",
        "      print('Existed: %s' % ckpt_folder)\n",
        "    else:\n",
        "      final_fn = 'step.tgz'\n",
        "      for i in range(ord('a'), ord('q')+1):\n",
        "        ch = chr(i)\n",
        "        fn = 'step_350000.tgz.parta%s' % chr(i)\n",
        "        print('donwloading: %s' % fn)\n",
        "        url = 'https://huggingface.co/patent/patentgpt-j-1.6B/resolve/main/%s' % fn\n",
        "        !wget $url\n",
        "        !cat $fn >> $final_fn\n",
        "        !rm $fn\n",
        "  !tar xfz step.tgz\n",
        "else: # using original GPT-J-6B\n",
        "  params_file = os.path.join('mesh-transformer-jax', 'configs', '6B_roto_256.json')\n",
        "  d_model = 4096\n",
        "  encoder_path = 'gpt2'\n",
        "  ckpt_folder = 'step_383500/'\n",
        "  if os.path.exists(ckpt_folder) == False:\n",
        "    !time wget -c https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\n",
        "    !time tar -I zstd -xf step_383500_slim.tar.zstd\n",
        "    print('Downloaded: %s' % ckpt_folder)    \n",
        "  else:\n",
        "    print('Existed: %s' % ckpt_folder)\n",
        "\n",
        "if os.path.exists('mesh-transformer-jax') == False:\n",
        "  !git clone https://github.com/kingoflolz/mesh-transformer-jax.git\n",
        "  !pip install mesh-transformer-jax/\n",
        "\n",
        "print('Checkpoint is ready.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB0KdsBbwEEh",
        "outputId": "43a7273e-9810-4f6c-b4af-d5620a9229ca",
        "cellView": "code"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "project: PatentGPT-J-456M\n",
            "--2022-05-16 03:44:12--  https://huggingface.co/patent/patentgpt-j-456M/raw/main/pgj_d_1024.json\n",
            "Resolving huggingface.co (huggingface.co)... 34.197.58.156, 3.210.158.153, 18.214.24.217, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.197.58.156|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 814 [application/json]\n",
            "Saving to: ‘pgj_d_1024.json’\n",
            "\n",
            "pgj_d_1024.json     100%[===================>]     814  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-16 03:44:12 (168 MB/s) - ‘pgj_d_1024.json’ saved [814/814]\n",
            "\n",
            "Downloaded: pgj_d_1024.json\n",
            "--2022-05-16 03:44:12--  https://huggingface.co/patent/patentgpt-j-456M/resolve/main/bpe_output.tgz\n",
            "Resolving huggingface.co (huggingface.co)... 34.197.58.156, 3.210.158.153, 18.214.24.217, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.197.58.156|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/51/6d/516d501174169d14a8973546dea0bb30d839231727da773bc6c65ab82a5f5595/6541333d806f4abdc7b0f4503ed39183c4fd0a6a901f01e2bbdc6089510052f8?response-content-disposition=attachment%3B%20filename%3D%22bpe_output.tgz%22 [following]\n",
            "--2022-05-16 03:44:12--  https://cdn-lfs.huggingface.co/repos/51/6d/516d501174169d14a8973546dea0bb30d839231727da773bc6c65ab82a5f5595/6541333d806f4abdc7b0f4503ed39183c4fd0a6a901f01e2bbdc6089510052f8?response-content-disposition=attachment%3B%20filename%3D%22bpe_output.tgz%22\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 52.84.18.102, 52.84.18.124, 52.84.18.77, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|52.84.18.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1131182 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘bpe_output.tgz’\n",
            "\n",
            "bpe_output.tgz      100%[===================>]   1.08M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-05-16 03:44:12 (18.9 MB/s) - ‘bpe_output.tgz’ saved [1131182/1131182]\n",
            "\n",
            "bpe_output/\n",
            "bpe_output/patentgpt-merges.txt\n",
            "bpe_output/patentgpt-vocab.json\n",
            "bpe_output/tokenizer.json\n",
            "Downloaded: bpe_output\n",
            "--2022-05-16 03:44:12--  https://huggingface.co/patent/patentgpt-j-456M/resolve/main/step.tgz\n",
            "Resolving huggingface.co (huggingface.co)... 34.197.58.156, 3.210.158.153, 18.214.24.217, ...\n",
            "Connecting to huggingface.co (huggingface.co)|34.197.58.156|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/51/6d/516d501174169d14a8973546dea0bb30d839231727da773bc6c65ab82a5f5595/d280df628fd22fefd82c8acc94a6bcb74042c26ed707c4f04abbe5f4df257cd2?response-content-disposition=attachment%3B%20filename%3D%22step.tgz%22 [following]\n",
            "--2022-05-16 03:44:12--  https://cdn-lfs.huggingface.co/repos/51/6d/516d501174169d14a8973546dea0bb30d839231727da773bc6c65ab82a5f5595/d280df628fd22fefd82c8acc94a6bcb74042c26ed707c4f04abbe5f4df257cd2?response-content-disposition=attachment%3B%20filename%3D%22step.tgz%22\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 52.84.18.102, 52.84.18.124, 52.84.18.77, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|52.84.18.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4984795962 (4.6G) [binary/octet-stream]\n",
            "Saving to: ‘step.tgz’\n",
            "\n",
            "step.tgz            100%[===================>]   4.64G  59.1MB/s    in 95s     \n",
            "\n",
            "2022-05-16 03:45:47 (50.3 MB/s) - ‘step.tgz’ saved [4984795962/4984795962]\n",
            "\n",
            "Cloning into 'mesh-transformer-jax'...\n",
            "remote: Enumerating objects: 791, done.\u001b[K\n",
            "remote: Total 791 (delta 0), reused 0 (delta 0), pack-reused 791\u001b[K\n",
            "Receiving objects: 100% (791/791), 320.01 KiB | 3.11 MiB/s, done.\n",
            "Resolving deltas: 100% (486/486), done.\n",
            "Processing ./mesh-transformer-jax\n",
            "Building wheels for collected packages: mesh-transformer\n",
            "  Building wheel for mesh-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mesh-transformer: filename=mesh_transformer-0.0.0-py3-none-any.whl size=26330 sha256=e5d45e9afaddf5673402d4dc7688e9548ba16733d5c86794d08893fc9bcec766\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/bd/89/b1f6b2f3d6b938d0c5812ee97756a1afd32521bea293543863\n",
            "Successfully built mesh-transformer\n",
            "Installing collected packages: mesh-transformer\n",
            "Successfully installed mesh-transformer-0.0.0\n",
            "Checkpoint is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sentiment_analysis.py\n",
        "import argparse\n",
        "import json\n",
        "import time\n",
        "import jax\n",
        "import numpy as np\n",
        "import optax\n",
        "import requests \n",
        "import jax.tools.colab_tpu\n",
        "import transformers\n",
        "import os\n",
        "\n",
        "from mesh_transformer import util\n",
        "from mesh_transformer.checkpoint import read_ckpt\n",
        "from mesh_transformer.checkpoint import read_ckpt_lowmem\n",
        "from mesh_transformer.sampling import nucleaus_sample\n",
        "from mesh_transformer.transformer_shard import CausalTransformer\n",
        "from jax.experimental import maps\n",
        "from mesh_transformer.util import clip_by_global_norm\n",
        "from jax.config import config\n",
        "from smart_open import open\n",
        "\n",
        "import pdb\n",
        "\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "# print(jax.devices())\n",
        "\n",
        "# Can the following solve the issue:\n",
        "# 2022-05-16 01:54:29.817720: W external/org_tensorflow/tensorflow/compiler/xla/python/tpu_driver/client/tpu_client.cc:606] TPU Execute is taking a long time. This might be due to a deadlock between multiple TPU cores or a very slow program.\n",
        "colab_tpu_addr = os.environ['COLAB_TPU_ADDR'].split(':')[0]\n",
        "url = f'http://{colab_tpu_addr}:8475/requestversion/tpu_driver0.1_dev20210607'\n",
        "requests.post(url)\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "context = \\\n",
        "\"\"\"Message: Support has been terrible for 2 weeks...\n",
        "Sentiment: Negative\n",
        "###\n",
        "Message: I love your API, it is simple and so fast!\n",
        "Sentiment: Positive\n",
        "###\n",
        "Message: It is really bad! How could it be possible? \n",
        "Sentiment: Negative\n",
        "###\n",
        "Message: The API is great. It is really good!\n",
        "Sentiment: Positive\n",
        "###\n",
        "Message: GPT-J has been released 2 months ago.\n",
        "Sentiment: Neutral\n",
        "###\n",
        "Message: Your team has been amazing, thanks!\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "max_count = 100\n",
        "top_p = 0.9\n",
        "temp = 0.75\n",
        "count = positive = negative = neutral = others = 0\n",
        "\n",
        "def parse_args():\n",
        "    # Parse command line arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--config\", type=str, default=None)\n",
        "    parser.add_argument(\"--encoder_path\", type=str)\n",
        "    parser.add_argument(\"--ckpt_folder\", type=str)\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "def generate_one_record(tokenizer, network, tokens, seq):\n",
        "  global count, positive, negative, neutral, others\n",
        "\n",
        "  start = time.time()\n",
        "  provided_ctx = len(tokens)\n",
        "  pad_amount = seq - provided_ctx\n",
        "  padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "  batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "  length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "\n",
        "  gen_length = 8 #512\n",
        "  output = network.generate(batched_tokens, length, gen_length, \n",
        "    {\"top_p\": np.ones(total_batch) * top_p, \n",
        "    \"temp\": np.ones(total_batch) * temp})\n",
        "  gen_text = ''\n",
        "  for idx, o in enumerate(output[1][0][:, :, 0]):\n",
        "    gen_text = str(tokenizer.decode(o)).strip()\n",
        "    if gen_text.startswith('Positive'):\n",
        "      positive += 1\n",
        "    elif gen_text.startswith('Negative'):\n",
        "      negative += 1\n",
        "    elif gen_text.startswith('Neutral'):\n",
        "      neutral += 1\n",
        "    else:\n",
        "      others += 1\n",
        "\n",
        "  count += 1\n",
        "  print('[ %s ][ positive: %s][ negative: %s][ neutral: %s][ others: %s] text = [%s]' % \n",
        "        (count, positive, negative, neutral, others, gen_text))\n",
        "  \n",
        "  # provided_ctx = len(tokens)\n",
        "  # pad_amount = seq - provided_ctx\n",
        "  # padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)\n",
        "  # batched_tokens = np.array([padded_tokens] * total_batch)\n",
        "  # length = np.ones(total_batch, dtype=np.uint32) * len(tokens)\n",
        "  # start = time.time()\n",
        "  # gen_len = 8\n",
        "  # output = network.generate(batched_tokens, length, gen_len, \n",
        "  #   {\"top_p\": np.ones(total_batch) * top_p, \n",
        "  #     \"temp\": np.ones(total_batch) * temp})\n",
        "\n",
        "  # samples = []\n",
        "  # decoded_tokens = output[1][0]\n",
        "  # for o in decoded_tokens[:, :, 0]:\n",
        "  #   gen_text = str(tokenizer.decode(o)).strip()\n",
        "  #   print('gen_text: %s' % gen_text)\n",
        "  # print(f\"completion done in {time.time() - start:06}s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    params = json.load(open(args.config))\n",
        "\n",
        "    gradient_accumulation_steps = params.get(\"gradient_accumulation_steps\", 1)\n",
        "    per_replica_batch = params[\"per_replica_batch\"]\n",
        "    cores_per_replica = params[\"cores_per_replica\"]\n",
        "\n",
        "    assert cores_per_replica <= 8\n",
        "\n",
        "    bucket = params[\"bucket\"]\n",
        "    model_dir = params[\"model_dir\"]\n",
        "    layers = params[\"layers\"]\n",
        "    d_model = params[\"d_model\"]\n",
        "    n_heads = params[\"n_heads\"]\n",
        "    n_vocab = params[\"n_vocab\"]\n",
        "    seq = params[\"seq\"]\n",
        "    norm = params[\"norm\"]\n",
        "\n",
        "    params[\"sampler\"] = nucleaus_sample\n",
        "    opt = optax.chain(\n",
        "        optax.scale(1 / gradient_accumulation_steps),\n",
        "        clip_by_global_norm(1),\n",
        "        optax.scale_by_adam(),\n",
        "        optax.additive_weight_decay(0),\n",
        "        optax.scale(-1),\n",
        "        optax.scale_by_schedule(util.gpt3_schedule(0, 1, 0, 0))\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "    print(f\"jax devices: {jax.device_count()}\")\n",
        "    print(f\"jax runtime initialized in {time.time() - start:.06}s\")\n",
        "\n",
        "    mesh_shape = (jax.device_count() // cores_per_replica, cores_per_replica)\n",
        "    devices = np.array(jax.devices()).reshape(mesh_shape)\n",
        "    total_batch = per_replica_batch * jax.device_count() // cores_per_replica\n",
        "\n",
        "    if args.encoder_path == 'gpt2':\n",
        "      params[\"optimizer\"] = optax.scale(0)\n",
        "      tokenizer = transformers.GPT2TokenizerFast.from_pretrained('gpt2')\n",
        "      tokens = tokenizer.encode(context)\n",
        "\n",
        "      maps.thread_resources.env = maps.ResourceEnv(maps.Mesh(devices, ('dp', 'mp')))\n",
        "      network = CausalTransformer(params)\n",
        "      network.state = read_ckpt_lowmem(network.state, \"step_383500/\", devices.shape[1])\n",
        "      network.state = network.move_xmap(network.state, np.zeros(cores_per_replica))\n",
        "\n",
        "      for i in range(max_count):\n",
        "        generate_one_record(tokenizer, network, tokens, seq)\n",
        "    else:\n",
        "      ckpt_folder = args.ckpt_folder # '/content/step_350000/'\n",
        "      print(f\"using checkpoint {ckpt_folder}\")\n",
        "      params[\"optimizer\"] = opt\n",
        "      tokenizer_file='%s/tokenizer.json' % args.encoder_path\n",
        "      print('tokenizer_file: %s' % tokenizer_file) \n",
        "      tokenizer = transformers.GPT2TokenizerFast(tokenizer_file=tokenizer_file)\n",
        "      tokens = tokenizer.encode(context)\n",
        "\n",
        "      with jax.experimental.maps.mesh(devices, ('dp', 'mp')):\n",
        "          network = CausalTransformer(params)\n",
        "          start = time.time()\n",
        "          network.state = read_ckpt(network.state, ckpt_folder, devices.shape[1])\n",
        "          #network.state = read_ckpt(network.state, f\"gs://{bucket}/{model_dir}/step_{ckpt_step}/\", devices.shape[1])\n",
        "          print(f\"network loaded in {time.time() - start:.06}s\")\n",
        "\n",
        "          local_shards = max(jax.local_device_count() // mesh_shape[1], 1)\n",
        "          del network.state[\"opt_state\"]\n",
        "          network.state = network.move_xmap(network.state, np.zeros(local_shards))\n",
        "\n",
        "          while True:\n",
        "              generate_one_record(tokenizer, network, tokens, seq)\n",
        "              if count >= max_count:\n",
        "                  print('done')\n",
        "                  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28ru1TWw7VNm",
        "outputId": "7feb93b3-132e-4c74-b912-3bf791206a8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sentiment_analysis.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cmd = f\"python sentiment_analysis.py --config {params_file} \" \\\n",
        "  f\"--encoder_path {encoder_path} --ckpt_folder {ckpt_folder}\"\n",
        "!$cmd "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtY89AieAMeB",
        "outputId": "e8a7d548-af60-4d28-93ad-89620aec8054"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax devices: 8\n",
            "jax runtime initialized in 23.9388s\n",
            "using checkpoint step_350000/\n",
            "tokenizer_file: bpe_output/tokenizer.json\n",
            "/usr/local/lib/python3.7/dist-packages/jax/experimental/maps.py:412: UserWarning: xmap is an experimental feature and probably has bugs!\n",
            "  warn(\"xmap is an experimental feature and probably has bugs!\")\n",
            "key shape (8, 2)\n",
            "in shape (1, 2048)\n",
            "dp 1\n",
            "mp 8\n",
            "Total parameters: 456418528\n",
            "read from disk/gcs in 7.23076s\n",
            "network loaded in 11.1466s\n",
            "2022-05-16 03:49:36.650143: W external/org_tensorflow/tensorflow/compiler/xla/python/tpu_driver/client/tpu_client.cc:606] TPU Execute is taking a long time. This might be due to a deadlock between multiple TPU cores or a very slow program.\n",
            "[ 1 ][ positive: 0][ negative: 0][ neutral: 0][ others: 1] text = [Quickness\n",
            "###\n",
            "Message:]\n",
            "[ 2 ][ positive: 1][ negative: 0][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: Not]\n",
            "[ 3 ][ positive: 2][ negative: 0][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: B]\n",
            "[ 4 ][ positive: 3][ negative: 0][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: A]\n",
            "[ 5 ][ positive: 4][ negative: 0][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: S]\n",
            "[ 6 ][ positive: 5][ negative: 0][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: H]\n",
            "[ 7 ][ positive: 6][ negative: 0][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: Y]\n",
            "[ 8 ][ positive: 7][ negative: 0][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: G]\n",
            "[ 9 ][ positive: 7][ negative: 1][ neutral: 0][ others: 1] text = [Negative\n",
            "###\n",
            "Message: What]\n",
            "[ 10 ][ positive: 8][ negative: 1][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: No]\n",
            "[ 11 ][ positive: 9][ negative: 1][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: What]\n",
            "[ 12 ][ positive: 10][ negative: 1][ neutral: 0][ others: 1] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 13 ][ positive: 10][ negative: 1][ neutral: 0][ others: 2] text = [Notice?\n",
            "Sentiment:]\n",
            "[ 14 ][ positive: 11][ negative: 1][ neutral: 0][ others: 2] text = [Positive\n",
            "###\n",
            "Message: H]\n",
            "[ 15 ][ positive: 12][ negative: 1][ neutral: 0][ others: 2] text = [Positive\n",
            "###\n",
            "Message: If]\n",
            "[ 16 ][ positive: 13][ negative: 1][ neutral: 0][ others: 2] text = [Positive\n",
            "###\n",
            "Message: Need]\n",
            "[ 17 ][ positive: 14][ negative: 1][ neutral: 0][ others: 2] text = [Positive\n",
            "###\n",
            "Message: So]\n",
            "[ 18 ][ positive: 14][ negative: 1][ neutral: 0][ others: 3] text = [Special\n",
            "#\n",
            "Message: It is]\n",
            "[ 19 ][ positive: 14][ negative: 1][ neutral: 0][ others: 4] text = [Correct\n",
            "###\n",
            "Message: Actual]\n",
            "[ 20 ][ positive: 14][ negative: 2][ neutral: 0][ others: 4] text = [Negative\n",
            "###\n",
            "Message: I]\n",
            "[ 21 ][ positive: 15][ negative: 2][ neutral: 0][ others: 4] text = [Positive\n",
            "###\n",
            "Message: Please]\n",
            "[ 22 ][ positive: 15][ negative: 3][ neutral: 0][ others: 4] text = [Negative\n",
            "###\n",
            "Message: Z]\n",
            "[ 23 ][ positive: 15][ negative: 3][ neutral: 0][ others: 5] text = [Notice: What is good?]\n",
            "[ 24 ][ positive: 16][ negative: 3][ neutral: 0][ others: 5] text = [Positive\n",
            "###\n",
            "Message: H]\n",
            "[ 25 ][ positive: 16][ negative: 3][ neutral: 0][ others: 6] text = [Yes\n",
            "###\n",
            "Message: No]\n",
            "[ 26 ][ positive: 16][ negative: 3][ neutral: 0][ others: 7] text = [Negated\n",
            "###\n",
            "Message:]\n",
            "[ 27 ][ positive: 17][ negative: 3][ neutral: 0][ others: 7] text = [Positive\n",
            "###\n",
            "Message: S]\n",
            "[ 28 ][ positive: 18][ negative: 3][ neutral: 0][ others: 7] text = [Positive\n",
            "###\n",
            "Message: A]\n",
            "[ 29 ][ positive: 18][ negative: 3][ neutral: 0][ others: 8] text = [Very good!\n",
            "Sentiment:]\n",
            "[ 30 ][ positive: 18][ negative: 3][ neutral: 0][ others: 9] text = [Easy\n",
            "###\n",
            "Message:]\n",
            "[ 31 ][ positive: 19][ negative: 3][ neutral: 0][ others: 9] text = [Positive\n",
            "###\n",
            "Message: It]\n",
            "[ 32 ][ positive: 20][ negative: 3][ neutral: 0][ others: 9] text = [Positive\n",
            "###\n",
            "Message: E]\n",
            "[ 33 ][ positive: 21][ negative: 3][ neutral: 0][ others: 9] text = [Positive\n",
            "###\n",
            "Message: An]\n",
            "[ 34 ][ positive: 22][ negative: 3][ neutral: 0][ others: 9] text = [Positive\n",
            "###\n",
            "Message: It]\n",
            "[ 35 ][ positive: 22][ negative: 4][ neutral: 0][ others: 9] text = [Negative\n",
            "###\n",
            "Message: G]\n",
            "[ 36 ][ positive: 23][ negative: 4][ neutral: 0][ others: 9] text = [Positive\n",
            "###\n",
            "Message: Not]\n",
            "[ 37 ][ positive: 23][ negative: 4][ neutral: 0][ others: 10] text = [No\n",
            "ABCD: The API is]\n",
            "[ 38 ][ positive: 23][ negative: 5][ neutral: 0][ others: 10] text = [Negative\n",
            "###\n",
            "Message: The]\n",
            "[ 39 ][ positive: 24][ negative: 5][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 40 ][ positive: 25][ negative: 5][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: It]\n",
            "[ 41 ][ positive: 26][ negative: 5][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: G]\n",
            "[ 42 ][ positive: 26][ negative: 6][ neutral: 0][ others: 10] text = [Negative\n",
            "###\n",
            "Message: your]\n",
            "[ 43 ][ positive: 27][ negative: 6][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: A]\n",
            "[ 44 ][ positive: 28][ negative: 6][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 45 ][ positive: 29][ negative: 6][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: Ar]\n",
            "[ 46 ][ positive: 30][ negative: 6][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: G]\n",
            "[ 47 ][ positive: 31][ negative: 6][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: It]\n",
            "[ 48 ][ positive: 32][ negative: 6][ neutral: 0][ others: 10] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 49 ][ positive: 32][ negative: 6][ neutral: 0][ others: 11] text = [Is so many people, you are not]\n",
            "[ 50 ][ positive: 33][ negative: 6][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: Y]\n",
            "[ 51 ][ positive: 34][ negative: 6][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: G]\n",
            "[ 52 ][ positive: 35][ negative: 6][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 53 ][ positive: 36][ negative: 6][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 54 ][ positive: 37][ negative: 6][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 55 ][ positive: 38][ negative: 6][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: May]\n",
            "[ 56 ][ positive: 39][ negative: 6][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 57 ][ positive: 40][ negative: 6][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: E]\n",
            "[ 58 ][ positive: 40][ negative: 7][ neutral: 0][ others: 11] text = [Negative\n",
            "###\n",
            "Message: The]\n",
            "[ 59 ][ positive: 41][ negative: 7][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: G]\n",
            "[ 60 ][ positive: 41][ negative: 8][ neutral: 0][ others: 11] text = [Negative\n",
            "###\n",
            "Message: There]\n",
            "[ 61 ][ positive: 42][ negative: 8][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: How]\n",
            "[ 62 ][ positive: 43][ negative: 8][ neutral: 0][ others: 11] text = [Positive\n",
            "###\n",
            "Message: I]\n",
            "[ 63 ][ positive: 43][ negative: 8][ neutral: 0][ others: 12] text = [X\n",
            "###\n",
            "Message: There]\n",
            "[ 64 ][ positive: 43][ negative: 8][ neutral: 0][ others: 13] text = [Possession\n",
            "###\n",
            "Message]\n",
            "[ 65 ][ positive: 44][ negative: 8][ neutral: 0][ others: 13] text = [Positive\n",
            "###\n",
            "Message: Y]\n",
            "[ 66 ][ positive: 45][ negative: 8][ neutral: 0][ others: 13] text = [Positive\n",
            "###\n",
            "Message: G]\n",
            "[ 67 ][ positive: 46][ negative: 8][ neutral: 0][ others: 13] text = [Positive\n",
            "###\n",
            "Message: What]\n",
            "[ 68 ][ positive: 47][ negative: 8][ neutral: 0][ others: 13] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 69 ][ positive: 47][ negative: 8][ neutral: 1][ others: 13] text = [Neutral\n",
            "###\n",
            "Message: What]\n",
            "[ 70 ][ positive: 47][ negative: 9][ neutral: 1][ others: 13] text = [Negative\n",
            "###\n",
            "Message: The]\n",
            "[ 71 ][ positive: 47][ negative: 9][ neutral: 1][ others: 14] text = [Upy\n",
            "Sentiment: Down]\n",
            "[ 72 ][ positive: 48][ negative: 9][ neutral: 1][ others: 14] text = [Positive\n",
            "###\n",
            "Message: B]\n",
            "[ 73 ][ positive: 48][ negative: 10][ neutral: 1][ others: 14] text = [Negative\n",
            "###\n",
            "Message: Y]\n",
            "[ 74 ][ positive: 49][ negative: 10][ neutral: 1][ others: 14] text = [Positive\n",
            "###\n",
            "Message: Y]\n",
            "[ 75 ][ positive: 50][ negative: 10][ neutral: 1][ others: 14] text = [Positive\n",
            "###\n",
            "Message: G]\n",
            "[ 76 ][ positive: 51][ negative: 10][ neutral: 1][ others: 14] text = [Positive\n",
            "###\n",
            "Message: Not]\n",
            "[ 77 ][ positive: 51][ negative: 10][ neutral: 1][ others: 15] text = [Empty\n",
            "###\n",
            "Message:]\n",
            "[ 78 ][ positive: 52][ negative: 10][ neutral: 1][ others: 15] text = [Positive\n",
            "###\n",
            "Message: G]\n",
            "[ 79 ][ positive: 52][ negative: 10][ neutral: 1][ others: 16] text = [Unauthorized\n",
            "###\n",
            "Message:]\n",
            "[ 80 ][ positive: 53][ negative: 10][ neutral: 1][ others: 16] text = [Positive\n",
            "###\n",
            "Message: Sh]\n",
            "[ 81 ][ positive: 54][ negative: 10][ neutral: 1][ others: 16] text = [Positive\n",
            "###\n",
            "Message: Sh]\n",
            "[ 82 ][ positive: 55][ negative: 10][ neutral: 1][ others: 16] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 83 ][ positive: 56][ negative: 10][ neutral: 1][ others: 16] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 84 ][ positive: 57][ negative: 10][ neutral: 1][ others: 16] text = [Positive\n",
            "###\n",
            "Message: D]\n",
            "[ 85 ][ positive: 58][ negative: 10][ neutral: 1][ others: 16] text = [Positive\n",
            "###\n",
            "Message: The]\n",
            "[ 86 ][ positive: 58][ negative: 10][ neutral: 1][ others: 17] text = [False\n",
            "###\n",
            "Message:]\n",
            "[ 87 ][ positive: 58][ negative: 10][ neutral: 1][ others: 18] text = [Salmon\n",
            "###\n",
            "Message:]\n",
            "[ 88 ][ positive: 59][ negative: 10][ neutral: 1][ others: 18] text = [Positive\n",
            "###\n",
            "Message: This]\n",
            "[ 89 ][ positive: 59][ negative: 10][ neutral: 1][ others: 19] text = [Uterine\n",
            "###\n",
            "Message]\n",
            "[ 90 ][ positive: 60][ negative: 10][ neutral: 1][ others: 19] text = [Positive\n",
            "###\n",
            "Message: Y]\n",
            "[ 91 ][ positive: 60][ negative: 10][ neutral: 1][ others: 20] text = [Reject: I just like 2000:]\n",
            "[ 92 ][ positive: 61][ negative: 10][ neutral: 1][ others: 20] text = [Positive\n",
            "###\n",
            "Message: H]\n",
            "[ 93 ][ positive: 61][ negative: 11][ neutral: 1][ others: 20] text = [Negative\n",
            "###\n",
            "Message: All]\n",
            "[ 94 ][ positive: 61][ negative: 12][ neutral: 1][ others: 20] text = [Negative\n",
            "###\n",
            "Message: There]\n",
            "[ 95 ][ positive: 61][ negative: 12][ neutral: 1][ others: 21] text = [Notable\n",
            "###\n",
            "Message:]\n",
            "[ 96 ][ positive: 61][ negative: 13][ neutral: 1][ others: 21] text = [Negative\n",
            "###\n",
            "Message: G]\n",
            "[ 97 ][ positive: 61][ negative: 13][ neutral: 1][ others: 22] text = [Good\n",
            "###\n",
            "Message: The]\n",
            "[ 98 ][ positive: 62][ negative: 13][ neutral: 1][ others: 22] text = [Positive\n",
            "###\n",
            "Message: What]\n",
            "[ 99 ][ positive: 62][ negative: 14][ neutral: 1][ others: 22] text = [Negative\n",
            "###\n",
            "Message: Rep]\n",
            "[ 100 ][ positive: 62][ negative: 15][ neutral: 1][ others: 22] text = [Negative\n",
            "###\n",
            "Message: The]\n",
            "done\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Sentiment Analysis by PatentGPT-J ",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}